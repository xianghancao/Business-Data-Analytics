{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cc1c19-950e-4a65-ab8b-f3003ccb3fdf",
   "metadata": {},
   "source": [
    "# 决策树的理论"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b42de9-4818-48a6-81f2-366beaa8044d",
   "metadata": {},
   "source": [
    "决策树是监督学习中最常用、最实用的方法之一。它既可用于解决回归任务，也可用于解决分类任务，而其分类任务被更多地用于实际应用，如广告推荐、商户分类等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df67ea3-70e4-43d2-87c0-b59c5fc6bbde",
   "metadata": {},
   "source": [
    "## 1. 一个例子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c4104-5ff3-4510-a40c-12702efaae66",
   "metadata": {},
   "source": [
    "我们以一个生活中常见的相亲例子，来开启决策树的介绍和讨论：\n",
    "\n",
    "一个眼光略高对自己婚姻伴侣略有要求的女青年**刘小姐**，熟练得在相亲网站上筛选着相亲对象。\n",
    "\n",
    "这个相亲网站有超过10万个真实注册用户，她固然可以直接设置一定的筛选规则，例如：“年龄在25～35之间”，“收入在中档以上”，“相貌较好”等条件，让网站在数据库里检索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b74aa-68f3-440f-b374-d0e43e646c61",
   "metadata": {},
   "source": [
    "<center><img src=\"image/xiangqin_decision.png\" alt=\"image/xiangqin_decision.png\" width=\"600\" height=\"228\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedc039-5ba9-4881-a2f4-45abc061e6da",
   "metadata": {},
   "source": [
    "但是你已经意识到了，这样的规则会过滤掉不符合其中一些条件，但是在其他条件上却很好的男性。有没有什么方法来解决这个问题呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65647341-0686-4f83-87ad-1aab8a4366a8",
   "metadata": {},
   "source": [
    "<center><img src=\"image/xiangqin_decision2.png\" alt=\"image/xiangqin_decision2.png\" width=\"600\" height=\"228\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f68a8f-4c64-45b0-b451-6bee71e327be",
   "metadata": {},
   "source": [
    "同时，当有新的男士资料被添加到服务器，刘小姐也不是每时每刻都在线，错过了，如何是好？\n",
    "\n",
    "我们希望用机器学习的方法，让机器习得刘小姐**对于另一半的偏好**。这样，机器就可以24小时全天候帮她把关，并及时通过短信和邮件通知刘小姐。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b198b4-95f8-4240-85a4-ff4508b82bea",
   "metadata": {},
   "source": [
    "## 2. 模型的训练和预测过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a044a3-f304-452d-8473-8f0aaa1b0d5d",
   "metadata": {},
   "source": [
    "首先，准备数据样本："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1f8a1-f7b1-47ef-b2f0-614fa924fa0d",
   "metadata": {},
   "source": [
    "1）根据过去的浏览记录，将刘小姐点“👍”的男士样本打上标签，“Yes”，点“👎”或者拉黑的男士样本打上“No”；  \n",
    "2）根据随机对照实验理论，将样本分为样本内（IS）和样本外（OOS），比例可设为8:2，前者用来训练模型，后者用来验证模型的分类能力 ；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a245312-44f5-4895-9ea7-9dee70c28e02",
   "metadata": {},
   "source": [
    "### 2.1 样本内（IS）训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f535263-d076-4bfc-9b3f-74be1c461f9f",
   "metadata": {},
   "source": [
    "训练过程如下：\n",
    "1. 从上至下的方向，创建决策树的根节点，将样本内的数据集放入根节点中；\n",
    "2. 依次选择各个属性，对属性的数值进行划分（大于等于属性的某个值和小于这个属性值），并计算划分后的纯度；\n",
    "3. 选择划分后纯度最高或者标签一致的属性，作为当前分叉的标准，标签一致的为叶节点，另一个为中间节点；\n",
    "4. 回到步骤3，并重复执行1-3，直到所有中间节点都划分为叶节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328464f8-a79b-4480-96cf-32b00d470354",
   "metadata": {},
   "source": [
    "![decision_train](image/decision_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d3183-6951-440c-b986-5c8203128c4e",
   "metadata": {},
   "source": [
    "模型训练完，也就是决策树生成完毕后，就可以将样本内的数据输入到模型中。然后，观察模型预测的结果和真实的标签，两者之间的差异，这代表了模型的学习能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2699e5a-ee80-4e07-9f11-85304001bae0",
   "metadata": {},
   "source": [
    "### 2.2 样本外（OOS）的评估以及未知样本的预测 \n",
    "在模型学习到**刘小姐**的偏好后，就可以在**刘小姐**不在线的时候，也可以帮助其筛选样本了。当输入新的未知标签的数据到模型，模型会根据已经训练后的决策树的路径，很多就可以对样本进行分类，属于“Yes”还是“No”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f633cbb-d786-4a2c-8ec4-eeb5a550d1d3",
   "metadata": {},
   "source": [
    "![decision_predict.png](image/decision_predict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd603875-d46f-4488-a48f-b0461055588e",
   "metadata": {},
   "source": [
    "##  3. 划分的选择\n",
    "关于决策树从最上面的**根节点**，到下面的**中间节点**以及末端的**叶节点**，如何划分，换句话说在每一次划分选择哪个属性进行划分，决定了决策树的形状。\n",
    "<center><img src=\"image/decision_select.png\" alt=\"image/decision_select.png\" width=\"600\" height=\"228\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9abda1-2545-4eda-87af-3bcdd16e9476",
   "metadata": {},
   "source": [
    "如何选择最优划分属性。一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点“纯度”（purity）越来越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2878efca-92f7-4eb3-8268-8f0b5aab732e",
   "metadata": {},
   "source": [
    "节点的Gini属性用于测量它的纯度：如果一个节点包含的所有训练样例全都是同一类别的，我们就说这个节点是纯的（Gini=0）。\n",
    "Gini计算如下：  \n",
    "\n",
    "$$\n",
    "G=\\sum^C_{i=1}(p(i)*(1-p(i)))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb3e07-ca70-48dc-8f07-a2e88b284374",
   "metadata": {},
   "source": [
    "## 4. 模型的性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00979d-9a05-436f-87ca-4bfb9e61d326",
   "metadata": {},
   "source": [
    "### 4.1 精度与错误率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fe668-3290-4184-891a-e431c007b76c",
   "metadata": {},
   "source": [
    "如何评估一个模型的好坏，一个自然而然的想法就是：模型给出的预测值与真实值进行对比。\n",
    "\n",
    "错误率：分类错误的样本数占样本总数的比例   \n",
    "精度：分类正确样本数占样本总数的比例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6798e-4756-4a77-ab0a-d63ac8130c54",
   "metadata": {},
   "source": [
    "精度计算如下：  \n",
    "\n",
    "$$\n",
    "accuracy(y,\\hat{y}) = \\frac{1}{n}\\sum^{n-1}_{i=0}1(\\hat{y}_i=y_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe69fd9-0c6b-41d9-8e4e-c7fabec2d4eb",
   "metadata": {},
   "source": [
    "$$\n",
    "错误率 = 1 - 精度\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32464a4b-1ce1-42bb-ba47-f3dc2d60a9eb",
   "metadata": {},
   "source": [
    "### 4.2 查全率与查准率（局部考量结果）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502eb8c1-3411-4789-ab3f-1f22526eb7d6",
   "metadata": {},
   "source": [
    "在二分类任务（类别为两类）中，假如我们定义'positive' 和 'negative' 为分类的预测结果， 而 'true' and 'false' 指的是该预测是否符合，可以得到以下表格。上表为英文，下表为中文翻译。记住！多分类任务（类别为3类及以上）没有查全率和查准率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216e844-1b38-4935-a766-8f5ed5a443f5",
   "metadata": {},
   "source": [
    "![decision_evaluate](image/decision_evaluate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82aa420-0c24-4a3f-90b8-826d7f2cc39e",
   "metadata": {},
   "source": [
    "查准率（准确率，precision） \n",
    "\n",
    "$$\n",
    "precision=\\frac{tp}{tp+fp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72a5ae-1100-4f32-9f5c-4d30b28412d0",
   "metadata": {},
   "source": [
    "查全率（也叫召回率，灵敏度，recall）\n",
    "\n",
    "$$\n",
    "recall = \\frac{tp}{tp+fn}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddda81e-47eb-4c24-8dc5-fcae9ab74c97",
   "metadata": {},
   "source": [
    "综合查准率与查全率\n",
    "\n",
    "$$\n",
    "F1 = \\frac{2\\times precision\\times recall}{precision+recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e472da-413d-4bb1-b61a-7d378fa069d8",
   "metadata": {},
   "source": [
    "从上图可以知道：\n",
    "\n",
    "**查准率**：是基于「预测数据」，考察「真正例」的占比。  \n",
    "**查全率**：是基于「真实数据」，考察「真正例」的占比。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6b80d-5a54-4cd6-8ca5-33e74a61cf53",
   "metadata": {},
   "source": [
    "来看看两个例子：  \n",
    "例子1：如：在病情诊断时，我们希望查准率越高越好，减少病情误判。这样就需要约束条件比较严苛，落在约束条件下的样本数量较小，查全率自然就小了。\n",
    "\n",
    "例子2：如：在逃犯搜捕过程中，我们希望不放过一个漏网之鱼，所以就希望查全率越高越好。这样就需要约束条件比较宽松，落在约束条件下的样本数量较大，查准率自然就小了。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
