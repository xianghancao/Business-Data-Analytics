{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d1ddb6-7679-43d5-ac0f-1b81b3ee5cd1",
   "metadata": {},
   "source": [
    "# 聚类\n",
    "![cluster_intro](image/cluster_intro.png)  \n",
    "\n",
    "聚类是一种无监督的学习，它将相似的对象归到同一个簇中。簇内的对象越相似，聚类的效果越好。\n",
    "该算法可以应用于客户价值分析、文本分类、基因识别、卫星图片分析、商业客户归类等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d512e-fdaf-4cfc-bb91-683cf2ed95e4",
   "metadata": {},
   "source": [
    "## 聚类和分类的不同\n",
    "聚类和分类的最大不同在于，分类的目标事先已知，而聚类则不一样。因为其产生的结果与分类相同，只是没有预先定义，聚类有时候也被称为无监督分类（unsupervised classification）。\n",
    "\n",
    "**聚类(Clustering)** ：是指把相似的数据划分到一起，具体划分的时候并不关心这一类的标签，目标就是把相似的数据聚合到一起，聚类是一种无监督学习(Unsupervised Learning)方法。\n",
    "\n",
    "**分类(Classification)** ：是把不同的数据划分开，其过程是通过训练数据集获得一个分类器，再通过分类器去预测未知数据，分类是一种监督学习(Supervised Learning)方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55e86d-6549-496a-a36b-06c98fc5e663",
   "metadata": {},
   "source": [
    "## 2. K-均值（K-Means）算法设计\n",
    "K-Means算法是聚类模型中一种最常见的算法。  \n",
    "K是指聚类的类别数量。被归为一类的数据点组成一个簇(cu第四声)。\n",
    "请问图中的K=？\n",
    "\n",
    "![K-Means](image/K-Means.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a62a2-e1ee-443a-bee0-d9386d150d37",
   "metadata": {},
   "source": [
    "### 2.1 算法步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ca304-6440-4260-b4e7-c1e28a3a9012",
   "metadata": {},
   "source": [
    "K均值(K-means)算法分为3个步骤：  \n",
    "**第1步，选择初始的簇中心，可以随机选择数据集中的样本；**  \n",
    "**第2步，使用相似度算法，计算样本和每个簇中心的距离，将每个样本分配到最近的簇中心所在的簇；**  \n",
    "**第3步，计算新的簇中心。**  \n",
    "**重复迭代第2和3步，直到簇中心在不同的迭代之间变化不大。**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3a168-8664-4b11-9412-37eaab221d93",
   "metadata": {},
   "source": [
    "在第2步中，相似对象归入同一簇，将不相似对象归到不同簇。相似这一概念取决于所选的相似度计算方法。\n",
    "![distance_algo](image/distance_algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0115a9e-0de4-4ea1-8665-7c8874b61a41",
   "metadata": {},
   "source": [
    "在第3步中，如何计算簇的中心呢？我们考虑最简单的三个点组成的三角形的中心。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875b3ac3-3652-4814-85e7-bf6bb3d19a1e",
   "metadata": {},
   "source": [
    "![triangle](image/triangle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90704e7b-0577-4a80-90fa-1492e08b4a67",
   "metadata": {},
   "source": [
    "三角形的质心公式： 如果三角形顶点的坐标为 A(x1, y1), B(x2, y2), C(x3, y3)， 则三角形质心的公式如下： 三角形的质心= ((x1+x2+x3)/3, (y1+y2+y3)/3)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed60f02-adc7-463e-9ee1-ce69d8c30dee",
   "metadata": {},
   "source": [
    "下面是K-Means算法的动态演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877354e6-08c1-4275-b71f-548cb5d1ad86",
   "metadata": {},
   "source": [
    "![algo](image/algo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594475a-43b4-4011-994e-ed54f9ed875f",
   "metadata": {},
   "source": [
    "### 2.2 K-均值算法的优缺点\n",
    "优点：步骤简单，使用编程语言容易实现。\n",
    "\n",
    "缺点：\n",
    "1. K-means算法中的k是事先给定的，但是往往对于k给多少难以估计\n",
    "\n",
    "2. 受初始点的位置影响大，尤其是当部分样本点为异常点的时候"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2da768-2b12-408e-a85e-8ecb4adfb697",
   "metadata": {},
   "source": [
    "## 3. 聚类算法家族\n",
    "当然，聚类算法不止K-Means一种。当数据集本身情况比较复杂，使得K-means聚类效果并不理想的时候，很多新的聚类算法被开发出来了。\n",
    "### 3.1 DBSCAN\n",
    "k-means算法对于凸性数据具有良好的效果，能够根据距离来讲数据分为球状类的簇，但对于非凸形状的数据点，就无能为力了，当k-means算法在环形数据的聚类时，我们看看会发生什么情况。\n",
    "![K-Means非凸](image/K-Means-feitu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197a0ae-9800-485c-bbb6-bb6da8859b71",
   "metadata": {},
   "source": [
    "从上图可以看到，kmeans聚类产生了错误的结果，这个时候就需要用到基于密度的聚类方法了，该方法需要定义两个参数$\\epsilon$和$M$，分别表示密度的邻域半径和邻域密度阈值。DBSCAN就是其中的典型。下图是一种极端的情况，数据集似环形，DBSCAN可以很好的进行聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75865b-26ca-416d-bb4f-ef280fe69799",
   "metadata": {},
   "source": [
    "![DBSCAN](image/DBSCAN.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a5cc1-4aa1-4460-9eed-07e1d6686668",
   "metadata": {},
   "source": [
    "### 3.2 高斯混合\n",
    "高斯混合模型（GMM）可以看做是k-means模型的一个优化。高斯混合模型试图找到多维高斯模型概率分布的混合表示，它假定所有的数据样本$x$由$k$个混合多元高斯分布组合成的混合分布生成。从而拟合出任意形状的数据分布。\n",
    "$$\n",
    "p(x) = \\sum_i \\alpha_{i=1}^k * p(x_i|\\mu)\n",
    "$$\n",
    "\n",
    "![GMM](image/GMM.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99649672-6434-4ed4-ad77-8ee0e099a41e",
   "metadata": {},
   "source": [
    "### 3.3 层次聚类\n",
    "层次的聚类方法（Hierarchical Clustering），从字面上理解，其是层次化的聚类，最终得出来的是树形结构。专业一点来说，层次聚类通过 计算不同类别数据点间的相似度 来创建一棵有层次的嵌套聚类树。\n",
    "\n",
    "其算法流程为：先将所有样本的每个点都看成一个簇，然后找出距离最小的两个簇进行合并，不断重复到预期簇或者其他终止条件。\n",
    "\n",
    "![HierarchicalClustering](image/HierarchicalClustering.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8b472-edb2-488a-9bf8-47e856b79ece",
   "metadata": {},
   "source": [
    "## 课后练习\n",
    "发挥想象力，\n",
    "设计一个你的聚类算法，写在草稿纸上：\n",
    "1. 请包括算法的流程\n",
    "2. 解释你算法的优势  \n",
    "\n",
    "提示：可以从k-means算法的K和means下手"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
